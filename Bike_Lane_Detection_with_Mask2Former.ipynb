{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9954503,
          "sourceType": "datasetVersion",
          "datasetId": 6122121
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Bike Lane Detection with Mask2Former ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamshishashikrishna/LearnAnalytics/blob/main/Bike_Lane_Detection_with_Mask2Former.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "andandand_roads_of_berlin_path = kagglehub.dataset_download('andandand/roads-of-berlin')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "pvMcKpOUjWKj"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bike Lane Detection using Mask2Former\n",
        "\n",
        "## 1. Introduction and Setup\n",
        "\n",
        "This notebook demonstrates how to use the Mask2Former model, pretrained on [Mapillary Vistas](https://www.mapillary.com/dataset/vistas),\n",
        "to detect bike lanes in urban scenes. We'll learn how to:\n",
        "- Load and prepare images for semantic segmentation\n",
        "- Use a pretrained model for inference\n",
        "- Visualize and interpret the results\n",
        "\n",
        "\n",
        "## 2. Model and Processor Setup\n",
        "\n",
        "Mask2Former is a semantic segmentation model. The Mapillary Vistas\n",
        "dataset includes 66 classes of street-level objects, including bike lanes (class 7).\n",
        "To load our model and processor we can write a function such as:\n",
        "\n",
        "```python\n",
        "def setup_model():\n",
        "    # Initialize model and processor\n",
        "    processor = AutoImageProcessor.from_pretrained(\n",
        "        \"facebook/mask2former-swin-large-mapillary-vistas-semantic\"\n",
        "    )\n",
        "    mask2former = Mask2FormerForUniversalSegmentation.from_pretrained(\n",
        "        \"facebook/mask2former-swin-large-mapillary-vistas-semantic\"\n",
        "    )\n",
        "    \n",
        "    # Move to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    mask2former.to(device)\n",
        "    \n",
        "    return processor, mask2former, device\n",
        "```\n",
        "\n",
        "## 3. Image Loading and Batch Processing\n",
        "\n",
        "We'll create functions to load and process images in batches. This is more efficient\n",
        "than processing single images, especially when using a GPU.\n",
        "\n",
        "```python\n",
        "def load_batch_images(image_paths, batch_size=4):\n",
        "    \"\"\"\n",
        "    Load a batch of images from given paths\n",
        "    \"\"\"\n",
        "    batch_images = []\n",
        "    for img_path in image_paths[:batch_size]:\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            batch_images.append(image)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {e}\")\n",
        "    return batch_images\n",
        "```\n",
        "\n",
        "## 4. Model Inference\n",
        "\n",
        "Here's a sample function to run inference on our batch of images.\n",
        "The model will identify all semantic segments in the images, but we'll\n",
        "focus specifically on bike lanes (class 7).\n",
        "\n",
        "```python\n",
        "def run_inference(processor, mask2former, batch_images, device):\n",
        "    # Prepare batch for processing\n",
        "    inputs = processor(images=batch_images, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    # Run inference\n",
        "    with torch.no_grad():\n",
        "        outputs = mask2former(**inputs)\n",
        "    \n",
        "    # Post-process results\n",
        "    predicted_maps = processor.post_process_semantic_segmentation(\n",
        "        outputs,\n",
        "        target_sizes=[[img.size[1], img.size[0]] for img in batch_images]\n",
        "    )\n",
        "    \n",
        "    return predicted_maps\n",
        "```\n",
        "\n",
        "\n",
        "## 5. Visualization\n",
        "\n",
        "To understand our results, we'll create a visualization function that shows\n",
        "the original images alongside the detected bike lanes.\n",
        "\n",
        "```python\n",
        "def visualize_bike_lanes(images, segmentation_maps, alpha=0.6):\n",
        "    \"\"\"\n",
        "    Visualize one batch of images with bike lanes highlighted\n",
        "    \"\"\"\n",
        "    batch_size = len(images)\n",
        "    \n",
        "    fig, axes = plt.subplots(batch_size, 2, figsize=(12, 4*batch_size))\n",
        "    if batch_size == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    for idx in range(batch_size):\n",
        "        # Original image\n",
        "        axes[idx, 0].imshow(images[idx])\n",
        "        axes[idx, 0].set_title('Original Image')\n",
        "        axes[idx, 0].axis('off')\n",
        "        \n",
        "        # Create bike lane overlay\n",
        "        image_array = np.array(images[idx])\n",
        "        seg_map = segmentation_maps[idx].cpu().numpy()\n",
        "        bike_lane_mask = seg_map == 7\n",
        "        \n",
        "        # Create overlay\n",
        "        overlay = image_array.copy()\n",
        "        overlay[bike_lane_mask] = [255, 0, 0]  # Red color for bike lanes\n",
        "        blended = (alpha * overlay + (1-alpha) * image_array).astype(np.uint8)\n",
        "        \n",
        "        # Display overlay\n",
        "        axes[idx, 1].imshow(blended)\n",
        "        axes[idx, 1].set_title('Bike Lane Detection')\n",
        "        axes[idx, 1].axis('off')\n",
        "        \n",
        "        # Add detection status\n",
        "        has_bike_lanes = np.any(bike_lane_mask)\n",
        "        text_color = 'green' if has_bike_lanes else 'red'\n",
        "        status_text = 'Bike Lanes Detected' if has_bike_lanes else 'No Bike Lanes Detected'\n",
        "        axes[idx, 1].text(0.5, -0.1, status_text,\n",
        "                         color=text_color,\n",
        "                         ha='center',\n",
        "                         transform=axes[idx, 1].transAxes,\n",
        "                         fontsize=10,\n",
        "                         fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "```"
      ],
      "metadata": {
        "_uuid": "78796a31-9053-418c-8569-75ccf5456b18",
        "_cell_guid": "a3626f6e-4d17-48bc-a9ce-2606d56e2d97",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "0K2lGochjWKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Inference"
      ],
      "metadata": {
        "_uuid": "ac8088de-e028-4a8a-8871-9a0954115b07",
        "_cell_guid": "00d0fb00-e6d1-4876-8152-96412ba695da",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "_HFESK5VjWKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
        "from PIL import Image\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def process_training_set(train_dir):\n",
        "    \"\"\"\n",
        "    Process all images in training set to detect bike lanes using Mask2Former\n",
        "\n",
        "    Args:\n",
        "        train_dir (str): Path to training directory containing images\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary mapping image paths to boolean indicating bike lane presence\n",
        "    \"\"\"\n",
        "    # Initialize model and processor with correct classes\n",
        "    processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-mapillary-vistas-semantic\")\n",
        "    mask2former = Mask2FormerForUniversalSegmentation.from_pretrained(\n",
        "        \"facebook/mask2former-swin-large-mapillary-vistas-semantic\"\n",
        "    )\n",
        "\n",
        "    # Move model to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    mask2former.to(device)\n",
        "\n",
        "    # Dictionary to store results\n",
        "    results = {}\n",
        "\n",
        "    # Get all image files recursively\n",
        "    image_files = []\n",
        "    for root, _, files in os.walk(train_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                image_files.append(os.path.join(root, file))\n",
        "\n",
        "    # Process images in batches\n",
        "    batch_size = 4  # Adjust based on your GPU memory\n",
        "\n",
        "    for i in tqdm(range(0, len(image_files), batch_size)):\n",
        "        batch_paths = image_files[i:i + batch_size]\n",
        "        batch_images = []\n",
        "\n",
        "        # Load and prepare batch\n",
        "        for img_path in batch_paths:\n",
        "            try:\n",
        "                image = Image.open(img_path).convert('RGB')\n",
        "                batch_images.append(image)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not batch_images:\n",
        "            continue\n",
        "\n",
        "        # Prepare batch for processing\n",
        "        inputs = processor(images=batch_images, return_tensors=\"pt\")\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Run inference\n",
        "        with torch.no_grad():\n",
        "            outputs = mask2former(**inputs)\n",
        "\n",
        "        # Post-process results\n",
        "        predicted_maps = processor.post_process_semantic_segmentation(\n",
        "            outputs,\n",
        "            target_sizes=[[img.size[1], img.size[0]] for img in batch_images]\n",
        "        )\n",
        "\n",
        "        # Check for bike lanes in each image\n",
        "        for img_path, pred_map in zip(batch_paths, predicted_maps):\n",
        "            # Mapillary Vistas class 7 corresponds to bike lanes\n",
        "            contains_bike_lane = torch.any(pred_map == 7).item()\n",
        "            results[img_path] = contains_bike_lane\n",
        "\n",
        "    return results\n",
        "\n",
        "def analyze_results(results):\n",
        "    \"\"\"\n",
        "    Analyze and print summary statistics of bike lane detection results\n",
        "\n",
        "    Args:\n",
        "        results (dict): Dictionary mapping image paths to bike lane detection results\n",
        "    \"\"\"\n",
        "    total_images = len(results)\n",
        "    images_with_lanes = sum(1 for v in results.values() if v)\n",
        "\n",
        "    print(f\"\\nAnalysis Results:\")\n",
        "    print(f\"Total images processed: {total_images}\")\n",
        "    print(f\"Images with bike lanes: {images_with_lanes} ({(images_with_lanes/total_images)*100:.2f}%)\")\n",
        "    print(f\"Images without bike lanes: {total_images - images_with_lanes} ({((total_images-images_with_lanes)/total_images)*100:.2f}%)\")"
      ],
      "metadata": {
        "_uuid": "5ab257fd-3597-4da3-a21b-4192a150290e",
        "_cell_guid": "04829411-0801-464d-8ef9-88ff4f931b1f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T22:31:31.321837Z",
          "iopub.execute_input": "2024-11-22T22:31:31.322107Z",
          "iopub.status.idle": "2024-11-22T22:31:49.614014Z",
          "shell.execute_reply.started": "2024-11-22T22:31:31.322081Z",
          "shell.execute_reply": "2024-11-22T22:31:49.612861Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6ove0eT3jWKm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Compute How Many of the Images Show a Bike Lane"
      ],
      "metadata": {
        "_uuid": "4ab26134-3067-4fba-90ed-bd497392175f",
        "_cell_guid": "72fff2f1-6a7c-462c-8e6b-fb90bbb4ee62",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "yJ7w2K0VjWKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "# You can also try images from the test folder, the model is pretrained.\n",
        "# We are not really using the training set to 'train' we only do inference\n",
        "train_dir = \"/kaggle/input/roads-of-berlin/train\"\n",
        "\n",
        "print(\"Starting bike lane detection on training set...\")\n",
        "results = process_training_set(train_dir)\n",
        "\n",
        "# Analyze results\n",
        "analyze_results(results)"
      ],
      "metadata": {
        "_uuid": "0d069b59-ec10-49a4-b1a9-af2ea6c006e2",
        "_cell_guid": "3d7d924b-5d10-4089-9be0-85a9e5594e2f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T22:31:49.616099Z",
          "iopub.execute_input": "2024-11-22T22:31:49.617425Z",
          "iopub.status.idle": "2024-11-22T22:33:36.531955Z",
          "shell.execute_reply.started": "2024-11-22T22:31:49.617372Z",
          "shell.execute_reply": "2024-11-22T22:33:36.531017Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "97u_FeHZjWKn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to file\n",
        "import json\n",
        "with open(\"bike_lane_detection_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "_uuid": "c7b87cc5-3d45-4aa9-b026-230a36f33642",
        "_cell_guid": "b1cd3291-de64-4a87-a689-7c599280cebb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T22:33:36.532885Z",
          "iopub.execute_input": "2024-11-22T22:33:36.533112Z",
          "iopub.status.idle": "2024-11-22T22:33:36.538525Z",
          "shell.execute_reply.started": "2024-11-22T22:33:36.533089Z",
          "shell.execute_reply": "2024-11-22T22:33:36.537724Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "BfkNKPnVjWKn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Visualize a batch of predictions"
      ],
      "metadata": {
        "_uuid": "e4b5a9c7-988d-4139-95bf-c4877102aa79",
        "_cell_guid": "fc3e854e-f034-4b75-b641-4afe659c26a6",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "2FtF-Pp0jWKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def visualize_bike_lanes(images, segmentation_maps, alpha=0.6):\n",
        "    \"\"\"\n",
        "    Visualize one batch of images with bike lanes highlighted\n",
        "\n",
        "    Args:\n",
        "        images: List of PIL images\n",
        "        segmentation_maps: List of segmentation maps\n",
        "        alpha: Transparency of the overlay (0-1)\n",
        "    \"\"\"\n",
        "    batch_size = len(images)\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(batch_size, 2, figsize=(12, 4*batch_size))\n",
        "    if batch_size == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for idx in range(batch_size):\n",
        "        # Original image\n",
        "        axes[idx, 0].imshow(images[idx])\n",
        "        axes[idx, 0].set_title('Original Image')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # Create bike lane overlay\n",
        "        image_array = np.array(images[idx])\n",
        "        seg_map = segmentation_maps[idx].cpu().numpy()\n",
        "\n",
        "        # Create mask for bike lanes (class 7)\n",
        "        bike_lane_mask = seg_map == 7\n",
        "\n",
        "        # Create overlay\n",
        "        overlay = image_array.copy()\n",
        "        # Add red highlight for bike lanes\n",
        "        overlay[bike_lane_mask] = [255, 0, 0]  # Red color for bike lanes\n",
        "\n",
        "        # Blend with original image\n",
        "        blended = (alpha * overlay + (1-alpha) * image_array).astype(np.uint8)\n",
        "\n",
        "        # Display overlay\n",
        "        axes[idx, 1].imshow(blended)\n",
        "        axes[idx, 1].set_title('Bike Lane Detection')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # Add text indicating if bike lanes were detected\n",
        "        has_bike_lanes = np.any(bike_lane_mask)\n",
        "        text_color = 'green' if has_bike_lanes else 'red'\n",
        "        status_text = 'Bike Lanes Detected' if has_bike_lanes else 'No Bike Lanes Detected'\n",
        "        axes[idx, 1].text(0.5, -0.1, status_text,\n",
        "                         color=text_color,\n",
        "                         ha='center',\n",
        "                         transform=axes[idx, 1].transAxes,\n",
        "                         fontsize=10,\n",
        "                         fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def process_and_visualize_batch(image_paths, batch_size=4):\n",
        "    # Initialize model and processor\n",
        "    processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-mapillary-vistas-semantic\")\n",
        "    mask2former = Mask2FormerForUniversalSegmentation.from_pretrained(\n",
        "        \"facebook/mask2former-swin-large-mapillary-vistas-semantic\"\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    mask2former.to(device)\n",
        "\n",
        "    # Load images\n",
        "    batch_images = []\n",
        "    for img_path in image_paths[:batch_size]:\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        batch_images.append(image)\n",
        "\n",
        "    # Process batch\n",
        "    inputs = processor(images=batch_images, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Run inference\n",
        "    with torch.no_grad():\n",
        "        outputs = mask2former(**inputs)\n",
        "\n",
        "    # Post-process results\n",
        "    predicted_maps = processor.post_process_semantic_segmentation(\n",
        "        outputs,\n",
        "        target_sizes=[[img.size[1], img.size[0]] for img in batch_images]\n",
        "    )\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_bike_lanes(batch_images, predicted_maps)\n",
        "\n",
        "    return batch_images, predicted_maps"
      ],
      "metadata": {
        "_uuid": "04e64aac-edb2-4184-b7e8-28a2f06afde3",
        "_cell_guid": "58d523dd-e4c3-4384-bc34-a6c11be77594",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T22:43:11.875925Z",
          "iopub.execute_input": "2024-11-22T22:43:11.876683Z",
          "iopub.status.idle": "2024-11-22T22:43:11.888838Z",
          "shell.execute_reply.started": "2024-11-22T22:43:11.876647Z",
          "shell.execute_reply": "2024-11-22T22:43:11.887939Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "COwXdUrGjWKn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "_uuid": "e388bca6-119f-4673-802e-738868729bb3",
        "_cell_guid": "3d1e175a-44ed-4045-bfef-b5ae04012a9d",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "xeviJbqwjWKo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/kaggle/input/roads-of-berlin/train\"\n",
        "\n",
        "# Get first few images from directory\n",
        "image_paths = []\n",
        "for root, _, files in os.walk(train_dir):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_paths.append(os.path.join(root, file))\n",
        "    if len(image_paths) >= 4:  # Just get enough for one batch\n",
        "        break\n",
        "\n",
        "# Process and visualize batch\n",
        "batch_images, predicted_maps = process_and_visualize_batch(image_paths)"
      ],
      "metadata": {
        "_uuid": "f2395ce9-040d-43b8-9107-027f2dfdb50d",
        "_cell_guid": "624eaced-d898-4d99-9bd4-28c887e9795b",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T22:43:17.053266Z",
          "iopub.execute_input": "2024-11-22T22:43:17.053585Z",
          "iopub.status.idle": "2024-11-22T22:43:20.977711Z",
          "shell.execute_reply.started": "2024-11-22T22:43:17.053558Z",
          "shell.execute_reply": "2024-11-22T22:43:20.976827Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "WPidggk7jWKo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Tasks"
      ],
      "metadata": {
        "_uuid": "682eedc3-bdb4-4988-bec6-be6874342803",
        "_cell_guid": "88d5ad18-13ca-487d-9aac-421d8287aa73",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "jq2lNkarjWKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Beginner Level**\n",
        "1. **Understand the Model and its Output**:\n",
        "   - Explain what [Mask2Former](https://arxiv.org/abs/2112.01527) is and its use in segmentation tasks.\n",
        "   - Visualize a mask that shows all classes that the model can label, not only bike lanes.\n",
        "     \n",
        "\n",
        "2. **Explore the Output on More Images**:\n",
        "   - Modify the code that shows the segmentations overlaid on the images so that you can see predictions on the next batches.\n",
        "   - Use the pretrained Mask2Former model on provided images from the test folder and visualize the output.\n",
        "\n",
        "---\n",
        "\n",
        "### **Intermediate Level**\n",
        "1. **Evaluate the Transformations of Preprocessing**:\n",
        "   - Visualize the output of the preprocessing transformations and explain the role that they have.\n",
        "\n",
        "2. **Quantify Percentage of Bike Lanes on Images**:\n",
        "   - Modify the plots to show the percentage of pixels in the image that show a bike lane\n",
        "\n",
        "3. **Experiment with Confidence Thresholds**:\n",
        "   - Experiment with model inference settings like confidence thresholds impact on results.\n",
        "  Consider using the following function to manipulate the outputs:\n",
        "\n",
        "```\n",
        "def run_inference_with_threshold(processor, mask2former, batch_images, device, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Run inference with adjustable confidence threshold\n",
        "    \n",
        "    Args:\n",
        "        processor: Mask2Former processor\n",
        "        mask2former: Mask2Former model\n",
        "        batch_images: List of input images\n",
        "        device: torch device\n",
        "        threshold: Confidence threshold for predictions (default: 0.5)\n",
        "    \"\"\"\n",
        "    # Prepare batch for processing\n",
        "    inputs = processor(images=batch_images, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    # Run inference\n",
        "    with torch.no_grad():\n",
        "        outputs = mask2former(**inputs)\n",
        "    \n",
        "    # Get logits for semantic segmentation\n",
        "    logits = outputs.logits  # Shape: (batch_size, num_classes, height, width)\n",
        "    \n",
        "    # Apply softmax to get probabilities\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    \n",
        "    # Get bike lane probabilities (class 7)\n",
        "    bike_lane_probs = probs[:, 7, :, :]\n",
        "    \n",
        "    # Apply threshold to bike lane predictions\n",
        "    bike_lane_mask = (bike_lane_probs > threshold).int()\n",
        "    \n",
        "    # Create final segmentation maps\n",
        "    predicted_maps = []\n",
        "    for idx in range(len(batch_images)):\n",
        "        # Create empty prediction map\n",
        "        pred_map = torch.zeros_like(bike_lane_mask[idx])\n",
        "        # Set bike lane pixels based on threshold\n",
        "        pred_map[bike_lane_mask[idx] == 1] = 7\n",
        "        predicted_maps.append(pred_map)\n",
        "    \n",
        "    return predicted_maps, bike_lane_probs\n",
        "```\n",
        "\n",
        "4. **Visualize Outputs with a Widget**:\n",
        "   - Create a small utility to visually compare the output of different prediction thresholds.\n",
        "\n",
        "5. **Incorporate Bike Lane Masks into an Image Embedding Pipeline**:\n",
        "   - Overlay bike lane masks into images before feeding them to a segmentation model. What effect does this have on image similarity queries?"
      ],
      "metadata": {
        "_uuid": "e3d52c02-504b-4644-9346-ba5907e81ebc",
        "_cell_guid": "1f1d0880-b463-42bd-83b0-92ccef8178b5",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "j4XREY4bjWKo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "_uuid": "af548ee2-0238-471a-a386-f8e117406618",
        "_cell_guid": "b3204eeb-f70f-4cc3-a971-56a74cb660d5",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "aMzfA-CNjWKo"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}