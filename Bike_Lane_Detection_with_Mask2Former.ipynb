{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9954503,
          "sourceType": "datasetVersion",
          "datasetId": 6122121
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Bike Lane Detection with Mask2Former ",
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b927c7a25b743a2a099dd272b407b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6fe9f1242f049a9a8c6242e337d17c8",
              "IPY_MODEL_19e1f1585e7f480792ed4255380e2da2",
              "IPY_MODEL_8cd5a48fbbc34239bd52b0a3a6deddaa"
            ],
            "layout": "IPY_MODEL_3c6fec0eb3f94868a6b0bafc58c99e18"
          }
        },
        "d6fe9f1242f049a9a8c6242e337d17c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2cb44f02f8143119864cf1a08cfb74b",
            "placeholder": "​",
            "style": "IPY_MODEL_ee668d9a052f44e4b06840b1bf9f2dcd",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "19e1f1585e7f480792ed4255380e2da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8139b15769a84a4297f5f911bc5a0d69",
            "max": 536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35638ced814a478b88fae5b7b9b01ff0",
            "value": 536
          }
        },
        "8cd5a48fbbc34239bd52b0a3a6deddaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_765a29f5d2874b84a6f7916bad29f8cb",
            "placeholder": "​",
            "style": "IPY_MODEL_0689358ed299463e9f35cf9473a0db44",
            "value": " 536/536 [00:00&lt;00:00, 31.1kB/s]"
          }
        },
        "3c6fec0eb3f94868a6b0bafc58c99e18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2cb44f02f8143119864cf1a08cfb74b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee668d9a052f44e4b06840b1bf9f2dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8139b15769a84a4297f5f911bc5a0d69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35638ced814a478b88fae5b7b9b01ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "765a29f5d2874b84a6f7916bad29f8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0689358ed299463e9f35cf9473a0db44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75d27a95379d4cb49a224a55019406e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5dfb4f6ddb343b1993c776d950cfc7f",
              "IPY_MODEL_0f9532ad00be45a6aedafa768c048d5e",
              "IPY_MODEL_c268748bf70249e6b4e2ac3e85516856"
            ],
            "layout": "IPY_MODEL_9a77e45c369149429a0f5b52e9ae90f7"
          }
        },
        "a5dfb4f6ddb343b1993c776d950cfc7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_721f5d55efb24151afa0e0ec40fb04e5",
            "placeholder": "​",
            "style": "IPY_MODEL_03b793f3686c4d84bbae9e3707a4394c",
            "value": "config.json: 100%"
          }
        },
        "0f9532ad00be45a6aedafa768c048d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_668125a6b2a045949aac88d74e4568a9",
            "max": 79477,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_271e384437c04ee5beb004c6cea53f96",
            "value": 79477
          }
        },
        "c268748bf70249e6b4e2ac3e85516856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4775dc83f652451c9e2e853e27f01d88",
            "placeholder": "​",
            "style": "IPY_MODEL_8a1042e2072544f38a36012f241e2784",
            "value": " 79.5k/79.5k [00:00&lt;00:00, 3.88MB/s]"
          }
        },
        "9a77e45c369149429a0f5b52e9ae90f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "721f5d55efb24151afa0e0ec40fb04e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b793f3686c4d84bbae9e3707a4394c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "668125a6b2a045949aac88d74e4568a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "271e384437c04ee5beb004c6cea53f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4775dc83f652451c9e2e853e27f01d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a1042e2072544f38a36012f241e2784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7165efcd16524396955bf916fe378d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8aacaaccfda44b07a4db2081390cbbbb",
              "IPY_MODEL_de4c0d861eac4cd588885efdd03df0c8",
              "IPY_MODEL_4f1e385b75f6451bab014c7bd4ee0f52"
            ],
            "layout": "IPY_MODEL_3b7ce15d964547e7b011160f252f5136"
          }
        },
        "8aacaaccfda44b07a4db2081390cbbbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3a6005821bd42b790944c543631bb39",
            "placeholder": "​",
            "style": "IPY_MODEL_9d3e88adad534e32ad2a994dc697396a",
            "value": "model.safetensors: 100%"
          }
        },
        "de4c0d861eac4cd588885efdd03df0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20cb15a6fb52420fa65f923a5a4a03fc",
            "max": 865964336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a508768458e422c9ca18a531713ebff",
            "value": 865964336
          }
        },
        "4f1e385b75f6451bab014c7bd4ee0f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a5e64ba72ba4d9083b9e54b65762dd8",
            "placeholder": "​",
            "style": "IPY_MODEL_0953fe4046124d82b483014c0070a605",
            "value": " 866M/866M [00:09&lt;00:00, 156MB/s]"
          }
        },
        "3b7ce15d964547e7b011160f252f5136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3a6005821bd42b790944c543631bb39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d3e88adad534e32ad2a994dc697396a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20cb15a6fb52420fa65f923a5a4a03fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a508768458e422c9ca18a531713ebff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a5e64ba72ba4d9083b9e54b65762dd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0953fe4046124d82b483014c0070a605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamshishashikrishna/LearnAnalytics/blob/main/Bike_Lane_Detection_with_Mask2Former.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "andandand_roads_of_berlin_path = kagglehub.dataset_download('andandand/roads-of-berlin')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvMcKpOUjWKj",
        "outputId": "1d30f58a-077f-456d-a155-7f8273b665bb"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/andandand/roads-of-berlin?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175M/175M [00:03<00:00, 60.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bike Lane Detection using Mask2Former\n",
        "\n",
        "## 1. Introduction and Setup\n",
        "\n",
        "This notebook demonstrates how to use the Mask2Former model, pretrained on [Mapillary Vistas](https://www.mapillary.com/dataset/vistas),\n",
        "to detect bike lanes in urban scenes. We'll learn how to:\n",
        "- Load and prepare images for semantic segmentation\n",
        "- Use a pretrained model for inference\n",
        "- Visualize and interpret the results\n",
        "\n",
        "\n",
        "## 2. Model and Processor Setup\n",
        "\n",
        "Mask2Former is a semantic segmentation model. The Mapillary Vistas\n",
        "dataset includes 66 classes of street-level objects, including bike lanes (class 7).\n",
        "To load our model and processor we can write a function such as:\n",
        "\n",
        "```python\n",
        "def setup_model():\n",
        "    # Initialize model and processor\n",
        "    processor = AutoImageProcessor.from_pretrained(\n",
        "        \"facebook/mask2former-swin-large-mapillary-vistas-semantic\"\n",
        "    )\n",
        "    mask2former = Mask2FormerForUniversalSegmentation.from_pretrained(\n",
        "        \"facebook/mask2former-swin-large-mapillary-vistas-semantic\"\n",
        "    )\n",
        "    \n",
        "    # Move to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    mask2former.to(device)\n",
        "    \n",
        "    return processor, mask2former, device\n",
        "```\n",
        "\n",
        "## 3. Image Loading and Batch Processing\n",
        "\n",
        "We'll create functions to load and process images in batches. This is more efficient\n",
        "than processing single images, especially when using a GPU.\n",
        "\n",
        "```python\n",
        "def load_batch_images(image_paths, batch_size=4):\n",
        "    \"\"\"\n",
        "    Load a batch of images from given paths\n",
        "    \"\"\"\n",
        "    batch_images = []\n",
        "    for img_path in image_paths[:batch_size]:\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            batch_images.append(image)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {e}\")\n",
        "    return batch_images\n",
        "```\n",
        "\n",
        "## 4. Model Inference\n",
        "\n",
        "Here's a sample function to run inference on our batch of images.\n",
        "The model will identify all semantic segments in the images, but we'll\n",
        "focus specifically on bike lanes (class 7).\n",
        "\n",
        "```python\n",
        "def run_inference(processor, mask2former, batch_images, device):\n",
        "    # Prepare batch for processing\n",
        "    inputs = processor(images=batch_images, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    # Run inference\n",
        "    with torch.no_grad():\n",
        "        outputs = mask2former(**inputs)\n",
        "    \n",
        "    # Post-process results\n",
        "    predicted_maps = processor.post_process_semantic_segmentation(\n",
        "        outputs,\n",
        "        target_sizes=[[img.size[1], img.size[0]] for img in batch_images]\n",
        "    )\n",
        "    \n",
        "    return predicted_maps\n",
        "```\n",
        "\n",
        "\n",
        "## 5. Visualization\n",
        "\n",
        "To understand our results, we'll create a visualization function that shows\n",
        "the original images alongside the detected bike lanes.\n",
        "\n",
        "```python\n",
        "def visualize_bike_lanes(images, segmentation_maps, alpha=0.6):\n",
        "    \"\"\"\n",
        "    Visualize one batch of images with bike lanes highlighted\n",
        "    \"\"\"\n",
        "    batch_size = len(images)\n",
        "    \n",
        "    fig, axes = plt.subplots(batch_size, 2, figsize=(12, 4*batch_size))\n",
        "    if batch_size == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    for idx in range(batch_size):\n",
        "        # Original image\n",
        "        axes[idx, 0].imshow(images[idx])\n",
        "        axes[idx, 0].set_title('Original Image')\n",
        "        axes[idx, 0].axis('off')\n",
        "        \n",
        "        # Create bike lane overlay\n",
        "        image_array = np.array(images[idx])\n",
        "        seg_map = segmentation_maps[idx].cpu().numpy()\n",
        "        bike_lane_mask = seg_map == 7\n",
        "        \n",
        "        # Create overlay\n",
        "        overlay = image_array.copy()\n",
        "        overlay[bike_lane_mask] = [255, 0, 0]  # Red color for bike lanes\n",
        "        blended = (alpha * overlay + (1-alpha) * image_array).astype(np.uint8)\n",
        "        \n",
        "        # Display overlay\n",
        "        axes[idx, 1].imshow(blended)\n",
        "        axes[idx, 1].set_title('Bike Lane Detection')\n",
        "        axes[idx, 1].axis('off')\n",
        "        \n",
        "        # Add detection status\n",
        "        has_bike_lanes = np.any(bike_lane_mask)\n",
        "        text_color = 'green' if has_bike_lanes else 'red'\n",
        "        status_text = 'Bike Lanes Detected' if has_bike_lanes else 'No Bike Lanes Detected'\n",
        "        axes[idx, 1].text(0.5, -0.1, status_text,\n",
        "                         color=text_color,\n",
        "                         ha='center',\n",
        "                         transform=axes[idx, 1].transAxes,\n",
        "                         fontsize=10,\n",
        "                         fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "```"
      ],
      "metadata": {
        "_uuid": "78796a31-9053-418c-8569-75ccf5456b18",
        "_cell_guid": "a3626f6e-4d17-48bc-a9ce-2606d56e2d97",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "0K2lGochjWKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Inference"
      ],
      "metadata": {
        "_uuid": "ac8088de-e028-4a8a-8871-9a0954115b07",
        "_cell_guid": "00d0fb00-e6d1-4876-8152-96412ba695da",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "_HFESK5VjWKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
        "from PIL import Image\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def process_training_set(train_dir):\n",
        "    \"\"\"\n",
        "    Process all images in training set to detect bike lanes using Mask2Former\n",
        "\n",
        "    Args:\n",
        "        train_dir (str): Path to training directory containing images\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary mapping image paths to boolean indicating bike lane presence\n",
        "    \"\"\"\n",
        "    # Initialize model and processor with correct classes\n",
        "    processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-mapillary-vistas-semantic\")\n",
        "    mask2former = Mask2FormerForUniversalSegmentation.from_pretrained(\n",
        "        \"facebook/mask2former-swin-large-mapillary-vistas-semantic\"\n",
        "    )\n",
        "\n",
        "    # Move model to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    mask2former.to(device)\n",
        "\n",
        "    # Dictionary to store results\n",
        "    results = {}\n",
        "\n",
        "    # Get all image files recursively\n",
        "    image_files = []\n",
        "    for root, _, files in os.walk(train_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                image_files.append(os.path.join(root, file))\n",
        "\n",
        "    # Process images in batches\n",
        "    batch_size = 4  # Adjust based on your GPU memory\n",
        "\n",
        "    for i in tqdm(range(0, len(image_files), batch_size)):\n",
        "        batch_paths = image_files[i:i + batch_size]\n",
        "        batch_images = []\n",
        "\n",
        "        # Load and prepare batch\n",
        "        for img_path in batch_paths:\n",
        "            try:\n",
        "                image = Image.open(img_path).convert('RGB')\n",
        "                batch_images.append(image)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not batch_images:\n",
        "            continue\n",
        "\n",
        "        # Prepare batch for processing\n",
        "        inputs = processor(images=batch_images, return_tensors=\"pt\")\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Run inference\n",
        "        with torch.no_grad():\n",
        "            outputs = mask2former(**inputs)\n",
        "\n",
        "        # Post-process results\n",
        "        predicted_maps = processor.post_process_semantic_segmentation(\n",
        "            outputs,\n",
        "            target_sizes=[[img.size[1], img.size[0]] for img in batch_images]\n",
        "        )\n",
        "\n",
        "        # Check for bike lanes in each image\n",
        "        for img_path, pred_map in zip(batch_paths, predicted_maps):\n",
        "            # Mapillary Vistas class 7 corresponds to bike lanes\n",
        "            contains_bike_lane = torch.any(pred_map == 7).item()\n",
        "            results[img_path] = contains_bike_lane\n",
        "\n",
        "    return results\n",
        "\n",
        "def analyze_results(results):\n",
        "    \"\"\"\n",
        "    Analyze and print summary statistics of bike lane detection results\n",
        "\n",
        "    Args:\n",
        "        results (dict): Dictionary mapping image paths to bike lane detection results\n",
        "    \"\"\"\n",
        "    total_images = len(results)\n",
        "    images_with_lanes = sum(1 for v in results.values() if v)\n",
        "\n",
        "    print(f\"\\nAnalysis Results:\")\n",
        "    print(f\"Total images processed: {total_images}\")\n",
        "    print(f\"Images with bike lanes: {images_with_lanes} ({(images_with_lanes/total_images)*100:.2f}%)\")\n",
        "    print(f\"Images without bike lanes: {total_images - images_with_lanes} ({((total_images-images_with_lanes)/total_images)*100:.2f}%)\")"
      ],
      "metadata": {
        "_uuid": "5ab257fd-3597-4da3-a21b-4192a150290e",
        "_cell_guid": "04829411-0801-464d-8ef9-88ff4f931b1f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T22:31:31.321837Z",
          "iopub.execute_input": "2024-11-22T22:31:31.322107Z",
          "iopub.status.idle": "2024-11-22T22:31:49.614014Z",
          "shell.execute_reply.started": "2024-11-22T22:31:31.322081Z",
          "shell.execute_reply": "2024-11-22T22:31:49.612861Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6ove0eT3jWKm"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Compute How Many of the Images Show a Bike Lane"
      ],
      "metadata": {
        "_uuid": "4ab26134-3067-4fba-90ed-bd497392175f",
        "_cell_guid": "72fff2f1-6a7c-462c-8e6b-fb90bbb4ee62",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "yJ7w2K0VjWKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "# You can also try images from the test folder, the model is pretrained.\n",
        "# We are not really using the training set to 'train' we only do inference\n",
        "train_dir = \"/kaggle/input/roads-of-berlin/train\"\n",
        "\n",
        "print(\"Starting bike lane detection on training set...\")\n",
        "results = process_training_set(train_dir)\n",
        "\n",
        "# Analyze results\n",
        "analyze_results(results)"
      ],
      "metadata": {
        "_uuid": "0d069b59-ec10-49a4-b1a9-af2ea6c006e2",
        "_cell_guid": "3d7d924b-5d10-4089-9be0-85a9e5594e2f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T22:31:49.616099Z",
          "iopub.execute_input": "2024-11-22T22:31:49.617425Z",
          "iopub.status.idle": "2024-11-22T22:33:36.531955Z",
          "shell.execute_reply.started": "2024-11-22T22:31:49.617372Z",
          "shell.execute_reply": "2024-11-22T22:33:36.531017Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646,
          "referenced_widgets": [
            "0b927c7a25b743a2a099dd272b407b0b",
            "d6fe9f1242f049a9a8c6242e337d17c8",
            "19e1f1585e7f480792ed4255380e2da2",
            "8cd5a48fbbc34239bd52b0a3a6deddaa",
            "3c6fec0eb3f94868a6b0bafc58c99e18",
            "b2cb44f02f8143119864cf1a08cfb74b",
            "ee668d9a052f44e4b06840b1bf9f2dcd",
            "8139b15769a84a4297f5f911bc5a0d69",
            "35638ced814a478b88fae5b7b9b01ff0",
            "765a29f5d2874b84a6f7916bad29f8cb",
            "0689358ed299463e9f35cf9473a0db44",
            "75d27a95379d4cb49a224a55019406e7",
            "a5dfb4f6ddb343b1993c776d950cfc7f",
            "0f9532ad00be45a6aedafa768c048d5e",
            "c268748bf70249e6b4e2ac3e85516856",
            "9a77e45c369149429a0f5b52e9ae90f7",
            "721f5d55efb24151afa0e0ec40fb04e5",
            "03b793f3686c4d84bbae9e3707a4394c",
            "668125a6b2a045949aac88d74e4568a9",
            "271e384437c04ee5beb004c6cea53f96",
            "4775dc83f652451c9e2e853e27f01d88",
            "8a1042e2072544f38a36012f241e2784",
            "7165efcd16524396955bf916fe378d80",
            "8aacaaccfda44b07a4db2081390cbbbb",
            "de4c0d861eac4cd588885efdd03df0c8",
            "4f1e385b75f6451bab014c7bd4ee0f52",
            "3b7ce15d964547e7b011160f252f5136",
            "c3a6005821bd42b790944c543631bb39",
            "9d3e88adad534e32ad2a994dc697396a",
            "20cb15a6fb52420fa65f923a5a4a03fc",
            "3a508768458e422c9ca18a531713ebff",
            "9a5e64ba72ba4d9083b9e54b65762dd8",
            "0953fe4046124d82b483014c0070a605"
          ]
        },
        "id": "97u_FeHZjWKn",
        "outputId": "54ac2543-9873-4e96-8d8b-4a0f14403557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting bike lane detection on training set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/536 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b927c7a25b743a2a099dd272b407b0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:165: UserWarning: The following named arguments are not valid for `Mask2FormerImageProcessor.__init__` and were ignored: '_max_size'\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/79.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75d27a95379d4cb49a224a55019406e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/866M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7165efcd16524396955bf916fe378d80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analysis Results:\n",
            "Total images processed: 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-dde67230ed6c>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Analyze results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0manalyze_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-75b56a9c11e6>\u001b[0m in \u001b[0;36manalyze_results\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nAnalysis Results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total images processed: {total_images}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Images with bike lanes: {images_with_lanes} ({(images_with_lanes/total_images)*100:.2f}%)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Images without bike lanes: {total_images - images_with_lanes} ({((total_images-images_with_lanes)/total_images)*100:.2f}%)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to file\n",
        "import json\n",
        "with open(\"bike_lane_detection_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "_uuid": "c7b87cc5-3d45-4aa9-b026-230a36f33642",
        "_cell_guid": "b1cd3291-de64-4a87-a689-7c599280cebb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T22:33:36.532885Z",
          "iopub.execute_input": "2024-11-22T22:33:36.533112Z",
          "iopub.status.idle": "2024-11-22T22:33:36.538525Z",
          "shell.execute_reply.started": "2024-11-22T22:33:36.533089Z",
          "shell.execute_reply": "2024-11-22T22:33:36.537724Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "BfkNKPnVjWKn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Visualize a batch of predictions"
      ],
      "metadata": {
        "_uuid": "e4b5a9c7-988d-4139-95bf-c4877102aa79",
        "_cell_guid": "fc3e854e-f034-4b75-b641-4afe659c26a6",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "2FtF-Pp0jWKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def visualize_bike_lanes(images, segmentation_maps, alpha=0.6):\n",
        "    \"\"\"\n",
        "    Visualize one batch of images with bike lanes highlighted\n",
        "\n",
        "    Args:\n",
        "        images: List of PIL images\n",
        "        segmentation_maps: List of segmentation maps\n",
        "        alpha: Transparency of the overlay (0-1)\n",
        "    \"\"\"\n",
        "    batch_size = len(images)\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(batch_size, 2, figsize=(12, 4*batch_size))\n",
        "    if batch_size == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for idx in range(batch_size):\n",
        "        # Original image\n",
        "        axes[idx, 0].imshow(images[idx])\n",
        "        axes[idx, 0].set_title('Original Image')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # Create bike lane overlay\n",
        "        image_array = np.array(images[idx])\n",
        "        seg_map = segmentation_maps[idx].cpu().numpy()\n",
        "\n",
        "        # Create mask for bike lanes (class 7)\n",
        "        bike_lane_mask = seg_map == 7\n",
        "\n",
        "        # Create overlay\n",
        "        overlay = image_array.copy()\n",
        "        # Add red highlight for bike lanes\n",
        "        overlay[bike_lane_mask] = [255, 0, 0]  # Red color for bike lanes\n",
        "\n",
        "        # Blend with original image\n",
        "        blended = (alpha * overlay + (1-alpha) * image_array).astype(np.uint8)\n",
        "\n",
        "        # Display overlay\n",
        "        axes[idx, 1].imshow(blended)\n",
        "        axes[idx, 1].set_title('Bike Lane Detection')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # Add text indicating if bike lanes were detected\n",
        "        has_bike_lanes = np.any(bike_lane_mask)\n",
        "        text_color = 'green' if has_bike_lanes else 'red'\n",
        "        status_text = 'Bike Lanes Detected' if has_bike_lanes else 'No Bike Lanes Detected'\n",
        "        axes[idx, 1].text(0.5, -0.1, status_text,\n",
        "                         color=text_color,\n",
        "                         ha='center',\n",
        "                         transform=axes[idx, 1].transAxes,\n",
        "                         fontsize=10,\n",
        "                         fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def process_and_visualize_batch(image_paths, batch_size=4):\n",
        "    # Initialize model and processor\n",
        "    processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-mapillary-vistas-semantic\")\n",
        "    mask2former = Mask2FormerForUniversalSegmentation.from_pretrained(\n",
        "        \"facebook/mask2former-swin-large-mapillary-vistas-semantic\"\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    mask2former.to(device)\n",
        "\n",
        "    # Load images\n",
        "    batch_images = []\n",
        "    for img_path in image_paths[:batch_size]:\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        batch_images.append(image)\n",
        "\n",
        "    # Process batch\n",
        "    inputs = processor(images=batch_images, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Run inference\n",
        "    with torch.no_grad():\n",
        "        outputs = mask2former(**inputs)\n",
        "\n",
        "    # Post-process results\n",
        "    predicted_maps = processor.post_process_semantic_segmentation(\n",
        "        outputs,\n",
        "        target_sizes=[[img.size[1], img.size[0]] for img in batch_images]\n",
        "    )\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_bike_lanes(batch_images, predicted_maps)\n",
        "\n",
        "    return batch_images, predicted_maps"
      ],
      "metadata": {
        "_uuid": "04e64aac-edb2-4184-b7e8-28a2f06afde3",
        "_cell_guid": "58d523dd-e4c3-4384-bc34-a6c11be77594",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T22:43:11.875925Z",
          "iopub.execute_input": "2024-11-22T22:43:11.876683Z",
          "iopub.status.idle": "2024-11-22T22:43:11.888838Z",
          "shell.execute_reply.started": "2024-11-22T22:43:11.876647Z",
          "shell.execute_reply": "2024-11-22T22:43:11.887939Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "COwXdUrGjWKn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "_uuid": "e388bca6-119f-4673-802e-738868729bb3",
        "_cell_guid": "3d1e175a-44ed-4045-bfef-b5ae04012a9d",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "xeviJbqwjWKo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/kaggle/input/roads-of-berlin/train\"\n",
        "\n",
        "# Get first few images from directory\n",
        "image_paths = []\n",
        "for root, _, files in os.walk(train_dir):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_paths.append(os.path.join(root, file))\n",
        "    if len(image_paths) >= 4:  # Just get enough for one batch\n",
        "        break\n",
        "\n",
        "# Process and visualize batch\n",
        "batch_images, predicted_maps = process_and_visualize_batch(image_paths)"
      ],
      "metadata": {
        "_uuid": "f2395ce9-040d-43b8-9107-027f2dfdb50d",
        "_cell_guid": "624eaced-d898-4d99-9bd4-28c887e9795b",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T22:43:17.053266Z",
          "iopub.execute_input": "2024-11-22T22:43:17.053585Z",
          "iopub.status.idle": "2024-11-22T22:43:20.977711Z",
          "shell.execute_reply.started": "2024-11-22T22:43:17.053558Z",
          "shell.execute_reply": "2024-11-22T22:43:20.976827Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "WPidggk7jWKo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Tasks"
      ],
      "metadata": {
        "_uuid": "682eedc3-bdb4-4988-bec6-be6874342803",
        "_cell_guid": "88d5ad18-13ca-487d-9aac-421d8287aa73",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "jq2lNkarjWKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Beginner Level**\n",
        "1. **Understand the Model and its Output**:\n",
        "   - Explain what [Mask2Former](https://arxiv.org/abs/2112.01527) is and its use in segmentation tasks.\n",
        "   - Visualize a mask that shows all classes that the model can label, not only bike lanes.\n",
        "     \n",
        "\n",
        "2. **Explore the Output on More Images**:\n",
        "   - Modify the code that shows the segmentations overlaid on the images so that you can see predictions on the next batches.\n",
        "   - Use the pretrained Mask2Former model on provided images from the test folder and visualize the output.\n",
        "\n",
        "---\n",
        "\n",
        "### **Intermediate Level**\n",
        "1. **Evaluate the Transformations of Preprocessing**:\n",
        "   - Visualize the output of the preprocessing transformations and explain the role that they have.\n",
        "\n",
        "2. **Quantify Percentage of Bike Lanes on Images**:\n",
        "   - Modify the plots to show the percentage of pixels in the image that show a bike lane\n",
        "\n",
        "3. **Experiment with Confidence Thresholds**:\n",
        "   - Experiment with model inference settings like confidence thresholds impact on results.\n",
        "  Consider using the following function to manipulate the outputs:\n",
        "\n",
        "```\n",
        "def run_inference_with_threshold(processor, mask2former, batch_images, device, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Run inference with adjustable confidence threshold\n",
        "    \n",
        "    Args:\n",
        "        processor: Mask2Former processor\n",
        "        mask2former: Mask2Former model\n",
        "        batch_images: List of input images\n",
        "        device: torch device\n",
        "        threshold: Confidence threshold for predictions (default: 0.5)\n",
        "    \"\"\"\n",
        "    # Prepare batch for processing\n",
        "    inputs = processor(images=batch_images, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    # Run inference\n",
        "    with torch.no_grad():\n",
        "        outputs = mask2former(**inputs)\n",
        "    \n",
        "    # Get logits for semantic segmentation\n",
        "    logits = outputs.logits  # Shape: (batch_size, num_classes, height, width)\n",
        "    \n",
        "    # Apply softmax to get probabilities\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    \n",
        "    # Get bike lane probabilities (class 7)\n",
        "    bike_lane_probs = probs[:, 7, :, :]\n",
        "    \n",
        "    # Apply threshold to bike lane predictions\n",
        "    bike_lane_mask = (bike_lane_probs > threshold).int()\n",
        "    \n",
        "    # Create final segmentation maps\n",
        "    predicted_maps = []\n",
        "    for idx in range(len(batch_images)):\n",
        "        # Create empty prediction map\n",
        "        pred_map = torch.zeros_like(bike_lane_mask[idx])\n",
        "        # Set bike lane pixels based on threshold\n",
        "        pred_map[bike_lane_mask[idx] == 1] = 7\n",
        "        predicted_maps.append(pred_map)\n",
        "    \n",
        "    return predicted_maps, bike_lane_probs\n",
        "```\n",
        "\n",
        "4. **Visualize Outputs with a Widget**:\n",
        "   - Create a small utility to visually compare the output of different prediction thresholds.\n",
        "\n",
        "5. **Incorporate Bike Lane Masks into an Image Embedding Pipeline**:\n",
        "   - Overlay bike lane masks into images before feeding them to a segmentation model. What effect does this have on image similarity queries?"
      ],
      "metadata": {
        "_uuid": "e3d52c02-504b-4644-9346-ba5907e81ebc",
        "_cell_guid": "1f1d0880-b463-42bd-83b0-92ccef8178b5",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "j4XREY4bjWKo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "_uuid": "af548ee2-0238-471a-a386-f8e117406618",
        "_cell_guid": "b3204eeb-f70f-4cc3-a971-56a74cb660d5",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "aMzfA-CNjWKo"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}